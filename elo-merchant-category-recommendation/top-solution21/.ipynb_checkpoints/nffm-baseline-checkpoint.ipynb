{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:04.878522Z",
     "start_time": "2019-02-13T08:49:04.438618Z"
    }
   },
   "outputs": [],
   "source": [
    "#Download ctrNet-tool \n",
    "#You can find the code in https://github.com/guoday/ctrNet-tool\n",
    "!git clone https://github.com/guoday/ctrNet-tool.git\n",
    "!cp -r ctrNet-tool/* ./\n",
    "# !rm -r ctrNet-tool data .git\n",
    "!ls -all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:05.081538Z",
     "start_time": "2019-02-13T08:49:05.071294Z"
    }
   },
   "outputs": [],
   "source": [
    "import ctrNet\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from src import misc_utils as utils\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "DEBUG = False\n",
    "\n",
    "NROWS = None\n",
    "\n",
    "if DEBUG:\n",
    "    NROWS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:06.066652Z",
     "start_time": "2019-02-13T08:49:06.055592Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from datetime import date, datetime\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "\n",
    "# import workalendar\n",
    "# from workalendar.america import Brazil\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(4590)\n",
    "\n",
    "skf= StratifiedKFold(n_splits=5, shuffle=True, random_state=4590)\n",
    "\n",
    "# by feature select \n",
    "# FILTER_FEATURE = ['new_hist_month_diff_min_-_hist_month_diff_min', 'new_hist_merchant_category_id_mean_mean_add_hist_merchant_category_id_mean_mean', 'new_hist_month_lag_mean_mean_add_hist_month_lag_mean_mean', 'hist_year_nunique', 'new_hist_month_diff_max_/_hist_month_diff_max', 'new_hist_merchant_id_mean_mean_add_hist_merchant_id_mean_mean', 'new_hist_month_diff_min_/_hist_month_diff_min', 'new_hist_year_mean_mean_add_hist_year_mean_mean', 'new_hist_dayofweek_mean_mean_/_hist_dayofweek_mean_mean', 'new_hist_weekofyear_mean_mean_add_hist_weekofyear_mean_mean', 'new_hist_dayofweek_nunique_/_hist_dayofweek_nunique', 'new_hist_month_diff_max', 'new_hist_year_mean_mean_/_hist_year_mean_mean', 'new_hist_merchant_category_id_mean_mean_/_hist_merchant_category_id_mean_mean', 'new_hist_merchant_id_mean_mean_/_hist_merchant_id_mean_mean', 'new_hist_year_nunique_/_hist_year_nunique', 'new_hist_month_diff_min', 'new_hist_merchant_category_id_mean_mean', 'hist_month_diff_mean_hist_month_diff_min_ctr', 'new_hist_year_nunique_-_hist_year_nunique', 'dayofweek', 'new_hist_month_mean_mean_/_hist_month_mean_mean', 'new_hist_month_diff_var', 'new_hist_installments_min_-_hist_installments_min', 'new_hist_subsector_id_mean_mean', 'new_hist_dayofweek_nunique', 'new_hist_weekend_mean', 'new_hist_category_2_mean_mean_/_hist_category_2_mean_mean', 'new_hist_merchant_category_id_nunique_-_hist_merchant_category_id_nunique', 'new_hist_month_diff_mean_add_hist_month_diff_mean', 'new_hist_authorized_flag_mean', 'new_hist_merchant_category_id_mean_mean_-_hist_merchant_category_id_mean_mean', 'new_hist_year_mean_mean_-_hist_year_mean_mean', 'new_hist_category_2_mean_mean', 'new_hist_card_id_mean_mean_add_hist_card_id_mean_mean', 'new_hist_month_diff_max_-_hist_month_diff_max', 'new_hist_weekend_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:06.741046Z",
     "start_time": "2019-02-13T08:49:06.702411Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../input/train.csv',nrows = NROWS)\n",
    "df_test = pd.read_csv('../input/test.csv',nrows = NROWS)\n",
    "df_hist_trans = pd.read_csv('../input/historical_transactions.csv',parse_dates=['purchase_date'], nrows = NROWS)\n",
    "df_new_merchant_trans = pd.read_csv('../input/new_merchant_transactions.csv',parse_dates=['purchase_date'], nrows = NROWS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:12.273742Z",
     "start_time": "2019-02-13T08:49:12.267220Z"
    }
   },
   "outputs": [],
   "source": [
    "max_date=df_new_merchant_trans['purchase_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:14.150618Z",
     "start_time": "2019-02-13T08:49:14.126869Z"
    },
    "_uuid": "520b71064293a20e0f2a379dad0acc274374a3c4"
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:16.285280Z",
     "start_time": "2019-02-13T08:49:16.154748Z"
    },
    "_uuid": "44198b73053869f8dfc083204c592fe9193f239c"
   },
   "outputs": [],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "df_hist_trans = reduce_mem_usage(df_hist_trans)\n",
    "df_new_merchant_trans = reduce_mem_usage(df_new_merchant_trans)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:17.431500Z",
     "start_time": "2019-02-13T08:49:17.414535Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:18.589328Z",
     "start_time": "2019-02-13T08:49:18.582682Z"
    },
    "_uuid": "dda90662d05e22310dd713df106ea07f4b8bccfc"
   },
   "outputs": [],
   "source": [
    "def get_new_columns(name,aggs):\n",
    "    return [name + '_' + k + '_' + agg for k in aggs.keys() for agg in aggs[k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:19.359109Z",
     "start_time": "2019-02-13T08:49:19.326045Z"
    },
    "_uuid": "7c91d3b9e9dbaff01962b0facbace75705a9ce18"
   },
   "outputs": [],
   "source": [
    "\n",
    "for df in [df_hist_trans,df_new_merchant_trans]:\n",
    "#     df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "    df['year'] = df['purchase_date'].dt.year\n",
    "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "    df['month'] = df['purchase_date'].dt.month\n",
    "    df['day'] = df['purchase_date'].dt.day\n",
    "    \n",
    "    df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "    df['weekend'] = (df.purchase_date.dt.weekday >=5).astype(int)\n",
    "    df['hour'] = df['purchase_date'].dt.hour\n",
    "    df['authorized_flag'] = df['authorized_flag'].map({'Y':1, 'N':0})\n",
    "    df['category_1'] = df['category_1'].map({'Y':1, 'N':0}) \n",
    "    df['month_diff'] = ((max_date - df['purchase_date']).dt.days)//30\n",
    "    df['month_diff'] += df['month_lag']\n",
    "#     df['authorized_flag_purchase_amount'] = df.apply(lambda x: x['purchase_amount'] \\\n",
    "#                             if x['authorized_flag']>0 else 0 ,axis=1)\n",
    "    \n",
    "#     df['unauthorized_flag_purchase_amount'] = df.apply(lambda x: x['purchase_amount'] \\\n",
    "#                             if x['authorized_flag']<1 else 0 ,axis=1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "                                                                           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:19.970238Z",
     "start_time": "2019-02-13T08:49:19.966576Z"
    }
   },
   "outputs": [],
   "source": [
    "# df_hist_trans.groupby('card_id')['month'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:21.715212Z",
     "start_time": "2019-02-13T08:49:21.306798Z"
    },
    "_uuid": "ddf1d5bb0ade2b22b0f072c208c1506ea64503ea"
   },
   "outputs": [],
   "source": [
    "def  get_agg_fea(count_df,prefix):\n",
    "    aggs = {}\n",
    "    for col in ['month','day','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id']:\n",
    "        aggs[col] = ['nunique']\n",
    "\n",
    "    aggs['purchase_amount'] = ['sum','max','min','mean','var']\n",
    "    aggs['installments'] = ['sum','max','min','mean','var']\n",
    "    aggs['purchase_date'] = ['max','min']\n",
    "    aggs['month_lag'] = ['max','min','mean','var']\n",
    "    # aggs['month_diff'] = ['mean']\n",
    "    aggs['month_diff'] = ['max','min','mean','var']\n",
    "    aggs['authorized_flag'] = ['sum', 'mean']\n",
    "    aggs['weekend'] = ['sum', 'mean']\n",
    "    aggs['category_1'] = ['sum', 'mean']\n",
    "    aggs['card_id'] = ['size']\n",
    "\n",
    "    for col in ['month','hour','weekofyear','dayofweek','year','subsector_id','merchant_id','merchant_category_id',\\\n",
    "                'category_1','category_2','category_3','month_lag','card_id']:\n",
    "        count_df[col+'_mean'] = count_df.groupby([col])['purchase_amount'].transform('mean')\n",
    "        aggs[col+'_mean'] = ['mean']   \n",
    "\n",
    "    new_columns = get_new_columns(prefix,aggs)\n",
    "    count_df_gp = count_df.groupby('card_id').agg(aggs)\n",
    "    count_df_gp.columns = new_columns\n",
    "    count_df_gp.reset_index(drop=False,inplace=True)\n",
    "    count_df_gp['%s_purchase_date_diff'%prefix] = (count_df_gp['%s_purchase_date_max'%prefix] - count_df_gp['%s_purchase_date_min'%prefix]).dt.days\n",
    "    count_df_gp['%s_purchase_date_average'%prefix] = count_df_gp['%s_purchase_date_diff'%prefix]/count_df_gp['%s_card_id_size'%prefix]\n",
    "    count_df_gp['%s_purchase_date_uptonow'%prefix] = (max_date - count_df_gp['%s_purchase_date_max'%prefix]).dt.days\n",
    "    count_df_gp['%s_purchase_date_uptomin'%prefix] = (max_date - count_df_gp['%s_purchase_date_min'%prefix]).dt.days\n",
    "    \n",
    "    return count_df_gp\n",
    "\n",
    "\n",
    "\n",
    "hist_count_df=get_agg_fea(df_hist_trans,'hist')\n",
    "df_train = df_train.merge(hist_count_df,on='card_id',how='left')\n",
    "df_test = df_test.merge(hist_count_df,on='card_id',how='left')\n",
    "del hist_count_df\n",
    "gc.collect()\n",
    "new_count_df = get_agg_fea(df_new_merchant_trans,'new_hist')\n",
    "df_train = df_train.merge(new_count_df,on='card_id',how='left')\n",
    "df_test = df_test.merge(new_count_df,on='card_id',how='left')\n",
    "del new_count_df\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:22.778036Z",
     "start_time": "2019-02-13T08:49:22.732980Z"
    }
   },
   "outputs": [],
   "source": [
    "for df in [df_train,df_test]:\n",
    "    \n",
    "    \n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    df['first_active_monthtonoew'] = ( max_date-pd.to_datetime(df['first_active_month'])).dt.days\n",
    "\n",
    "    df['dayofweek'] = df['first_active_month'].dt.dayofweek\n",
    "    df['weekofyear'] = df['first_active_month'].dt.weekofyear\n",
    "    df['month'] = df['first_active_month'].dt.month\n",
    "    df['elapsed_time'] = (max_date- df['first_active_month']).dt.days\n",
    "    df['hist_first_buy'] = (df['hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['new_hist_first_buy'] = (df['new_hist_purchase_date_min'] - df['first_active_month']).dt.days\n",
    "    df['hist_sleep_day'] = df['first_active_monthtonoew'] - df['hist_day_nunique']\n",
    "    df['new_sleep_day'] = df['first_active_monthtonoew'] - df['new_hist_day_nunique']\n",
    "    df['total_sleep_day'] = df['hist_sleep_day'] + df['new_sleep_day'] \n",
    "    df['diff_sleep_day'] = df['hist_sleep_day'] - df['new_sleep_day']\n",
    "   \n",
    "    \n",
    "    for f in ['hist_purchase_date_max','hist_purchase_date_min','new_hist_purchase_date_max',\\\n",
    "                     'new_hist_purchase_date_min']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9\n",
    "    \n",
    "    df['purchase_amount_total'] = df['new_hist_purchase_amount_sum']+df['hist_purchase_amount_sum']\n",
    "\n",
    "    \n",
    "    df['purchase_amount_diff'] = df['new_hist_purchase_amount_sum']-df['hist_purchase_amount_sum']\n",
    "    df['purchase_amount_rate'] = df['purchase_amount_diff']/df['hist_purchase_amount_sum']\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:36.775108Z",
     "start_time": "2019-02-13T08:49:23.470445Z"
    }
   },
   "outputs": [],
   "source": [
    "new_hist_feature=[ i for i in df_train  if 'new_hist' in i]\n",
    "\n",
    "for fea in new_hist_feature:\n",
    "    if fea in ['new_hist_purchase_date_max','new_hist_purchase_date_min']:\n",
    "        continue\n",
    "    print(fea)\n",
    "    new_fea=fea\n",
    "    hist_fea=fea.replace(\"new_hist\",'hist')\n",
    "    df_train[new_fea+\"_add_\"+hist_fea]=df_train[new_fea]+df_train[hist_fea]\n",
    "    df_test[new_fea+\"_add_\"+hist_fea]=df_test[new_fea]+df_test[hist_fea]\n",
    "    df_train[new_fea+\"_-_\"+hist_fea]=df_train[new_fea]-df_train[hist_fea]\n",
    "    df_test[new_fea+\"_-_\"+hist_fea]=df_test[new_fea]-df_test[hist_fea]\n",
    "    df_train[new_fea+\"_/_\"+hist_fea]=df_train[new_fea]/(df_train[hist_fea]+0.01)\n",
    "    df_test[new_fea+\"_/_\"+hist_fea]=df_test[new_fea]/(df_test[hist_fea]+0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:36.787285Z",
     "start_time": "2019-02-13T08:49:36.777129Z"
    },
    "_uuid": "6f3182aeac0c3bf7a061a1b9e25e859f25fee9b5"
   },
   "outputs": [],
   "source": [
    "df_train['outliers'] = 0\n",
    "df_train.loc[df_train['target'] < -30, 'outliers'] = 1\n",
    "df_train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:49:45.856849Z",
     "start_time": "2019-02-13T08:49:45.825671Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:50:15.390715Z",
     "start_time": "2019-02-13T08:50:15.383929Z"
    },
    "_uuid": "e9f61512c195c66a75dfe220072c5b2d860b78a3"
   },
   "outputs": [],
   "source": [
    "# Dealing with the one nan in df_test.first_active_month a bit arbitrarily for now\n",
    "try:\n",
    "    df_test.loc[df_test['first_active_month'].isna(),'first_active_month'] = df_test.iloc[11577]['first_active_month']\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:50:18.647475Z",
     "start_time": "2019-02-13T08:50:18.247354Z"
    },
    "_uuid": "a93c5976d3b395ba8ff0d1002b8075be3e914c54"
   },
   "outputs": [],
   "source": [
    "df_train = reduce_mem_usage(df_train)\n",
    "df_test = reduce_mem_usage(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:50:24.421772Z",
     "start_time": "2019-02-13T08:50:24.411019Z"
    }
   },
   "outputs": [],
   "source": [
    "bed_fea = ['new_hist_month_diff_min_-_hist_month_diff_min', 'new_hist_year_mean_mean_/_hist_year_mean_mean', 'new_hist_year_nunique_/_hist_year_nunique', 'new_hist_year_mean_mean_add_hist_year_mean_mean', 'new_hist_merchant_category_id_mean_mean_-_hist_merchant_category_id_mean_mean', 'new_hist_month_lag_mean_mean_-_hist_month_lag_mean_mean', 'new_hist_month_diff_max_add_hist_month_diff_max', 'new_hist_month_diff_min', 'new_hist_weekend_sum_/_hist_weekend_sum', 'new_hist_year_mean_mean', 'new_hist_merchant_id_mean_mean_add_hist_merchant_id_mean_mean', 'new_hist_purchase_amount_sum_-_hist_purchase_amount_sum', 'new_hist_month_diff_var', 'new_hist_month_diff_max_/_hist_month_diff_max', 'new_hist_weekofyear_nunique', 'new_hist_month_diff_max_-_hist_month_diff_max', 'new_hist_weekend_mean_add_hist_weekend_mean', 'new_hist_month_mean_mean_-_hist_month_mean_mean', 'new_hist_month_diff_mean', 'hist_year_nunique', 'new_hist_weekend_mean', 'new_hist_year_mean_mean_-_hist_year_mean_mean', 'hist_month_diff_mean_hist_month_diff_min_ctr', 'hist_dayofweek_nunique', 'new_hist_merchant_category_id_mean_mean', 'new_hist_weekend_sum', 'new_hist_installments_min_-_hist_installments_min', 'new_hist_authorized_flag_mean', 'new_hist_weekend_mean_/_hist_weekend_mean', 'hist_month_diff_min', 'new_hist_card_id_mean_mean_add_hist_card_id_mean_mean', 'new_hist_month_mean_mean_/_hist_month_mean_mean', 'new_hist_category_2_mean_mean', 'new_hist_month_diff_min_/_hist_month_diff_min', 'new_hist_merchant_category_id_mean_mean_add_hist_merchant_category_id_mean_mean', 'new_hist_dayofweek_nunique_/_hist_dayofweek_nunique', 'new_hist_month_mean_mean', 'new_hist_day_nunique_add_hist_day_nunique', 'new_hist_subsector_id_nunique_-_hist_subsector_id_nunique', 'new_hist_purchase_amount_max_add_hist_purchase_amount_max', 'new_hist_month_diff_mean_add_hist_month_diff_mean', 'new_hist_subsector_id_mean_mean', 'new_hist_year_nunique_-_hist_year_nunique', 'new_hist_dayofweek_nunique_-_hist_dayofweek_nunique', 'new_hist_merchant_id_mean_mean_/_hist_merchant_id_mean_mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:50:25.614391Z",
     "start_time": "2019-02-13T08:50:25.606309Z"
    },
    "_uuid": "c4f20f27679889542acfd60d1f1ac381b201ac43"
   },
   "outputs": [],
   "source": [
    "# bed_fea =['new_hist_month_diff_min', 'new_hist_authorized_flag_mean', 'new_hist_year_mean_mean', 'new_hist_year_nunique_/_hist_year_nunique', 'new_hist_year_nunique_-_hist_year_nunique']\n",
    "del_col =  ['card_id', 'first_active_month','target','outliers']+bed_fea\n",
    "\n",
    "features = [c for c in df_train.columns if c not in del_col ]\n",
    "\n",
    "target = df_train['outliers']\n",
    "\n",
    "train_y = target \n",
    "# df_train.drop(columns  = [\"card_id\",\"target\"],inplace=True)\n",
    "# df_test.drop(columns = [\"card_id\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:50:26.670421Z",
     "start_time": "2019-02-13T08:50:26.665289Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:50:27.748849Z",
     "start_time": "2019-02-13T08:50:27.735728Z"
    }
   },
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:50:53.132661Z",
     "start_time": "2019-02-13T08:50:53.110986Z"
    }
   },
   "outputs": [],
   "source": [
    "hparam=tf.contrib.training.HParams(\n",
    "            model='nffm',\n",
    "            norm=True,\n",
    "            batch_norm_decay=0.9,\n",
    "            hidden_size=[128,128],\n",
    "            k=16,\n",
    "            hash_ids=int(2e5),\n",
    "            batch_size= 32,\n",
    "            optimizer=\"adam\",\n",
    "            learning_rate=0.001,\n",
    "            num_display_steps=1000,\n",
    "            num_eval_steps=1000,\n",
    "            epoch=1,\n",
    "            metric='auc',\n",
    "            init_method='uniform',\n",
    "            init_value=0.1,\n",
    "            feature_nums=len(features))\n",
    "utils.print_hparams(hparam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:54:55.490585Z",
     "start_time": "2019-02-13T08:54:54.543960Z"
    }
   },
   "outputs": [],
   "source": [
    "float_features = []\n",
    "\n",
    "for i in  features:\n",
    "    df_train[i].fillna(1e10,inplace=True)\n",
    "    df_test[i].fillna(1e10,inplace=True)\n",
    "    df_train[i] = df_train[i].apply(lambda x: round(x)).astype(int)\n",
    "    df_test[i] = df_test[i].apply(lambda x: round(x)).astype(int)\n",
    "    print(i,df_train[i].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##分桶\n",
    "def make_bucket(data,num=10):\n",
    "    data.sort()\n",
    "    bins=[]\n",
    "    for i in range(num):\n",
    "        bins.append(data[int(len(data)*(i+1)//num)-1])\n",
    "    return bins\n",
    "for f in features:\n",
    "    if df_train[i].nunique()>100:\n",
    "        df_train[f]=df_train[f].fillna(1e10)\n",
    "        df_test[f]=df_test[f].fillna(1e10)\n",
    "        data=list(df_train[f])+list(df_test[f])\n",
    "        bins=make_bucket(data,num=100)\n",
    "        df_train[f]=np.digitize(df_train[f],bins=bins)\n",
    "        df_test[f]=np.digitize(df_test[f],bins=bins)\n",
    "    \n",
    "features=df_train.columns.tolist()[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T08:59:56.971603Z",
     "start_time": "2019-02-13T08:59:56.959430Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test['outliers'] = 0  #郭大代码的bug 必须传个label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-13T09:01:06.727197Z",
     "start_time": "2019-02-13T09:00:06.818322Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import  StratifiedKFold\n",
    "from sklearn import  metrics\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=15)\n",
    "oof_train = np.zeros((len(df_train),1))\n",
    "oof_test = np.zeros((len(df_test),1))\n",
    "score_csv = []\n",
    "for fold,(trn_idx,val_idx) in enumerate (skf.split(df_train,df_train['outliers'])):\n",
    "    print(\"开始第 %d 折训练\"%(fold+1))\n",
    "    x_tr,x_val = df_train.iloc[trn_idx][features],df_train.iloc[val_idx][features]\n",
    "    y_tr,y_val = df_train['outliers'].iloc[trn_idx],df_train['outliers'][val_idx]\n",
    "    model = ctrNet.build_model(hparam)\n",
    "    model.df_train(df_train_data = (x_tr,y_tr),dev_data=(x_val,y_val))\n",
    "    del x_tr,y_tr\n",
    "    gc.collect()\n",
    "    predictions = model.infer(dev_data=(x_val,y_val))\n",
    "    oof_train[val_idx] = predictions.reshape(-1,1)\n",
    "    false_positive_rate, recall, thresholds = metrics.roc_curve(y_val, predictions)\n",
    "    score = metrics.auc(false_positive_rate, recall)\n",
    "    print(\"auc score %s\"%score)\n",
    "    score_csv.append(score)\n",
    "    del x_val,y_val\n",
    "    gc.collect()\n",
    "    oof_test = model.infer(dev_data=(df_test[features],df_test['outliers'])).reshape(-1,1)/5\n",
    "    \n",
    "mean_score = np.mean(score_csv)\n",
    "print(\"mean score %s\"%mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T10:30:18.442948Z",
     "start_time": "2019-02-12T10:30:18.435786Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, precision_recall_curve\n",
    "def threshold_search(y_true, y_proba, plot=False):\n",
    "    precision, recall, thresholds = precision_recall_curve(y_true, y_proba)\n",
    "    thresholds = np.append(thresholds, 1.001) \n",
    "    F = 2 / (1/precision + 1/recall)\n",
    "    best_score = np.max(F)\n",
    "    best_th = thresholds[np.argmax(F)]\n",
    "    if plot:\n",
    "        plt.plot(thresholds, F, '-b')\n",
    "        plt.plot([best_th], [best_score], '*r')\n",
    "        plt.show()\n",
    "    search_result = {'threshold': best_th , 'f1': best_score}\n",
    "    return search_result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T10:30:23.791284Z",
     "start_time": "2019-02-12T10:30:23.741487Z"
    }
   },
   "outputs": [],
   "source": [
    "threshold_search(train_y.values,oof_train.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T10:35:13.122752Z",
     "start_time": "2019-02-12T10:35:12.093343Z"
    }
   },
   "outputs": [],
   "source": [
    "train_prob=pd.DataFrame(oof_train)\n",
    "train_prob.columns=['class1']\n",
    "train_prob.to_csv(\"class_oof/train_prob_%s.csv\"%mean_loss,index=False)\n",
    "\n",
    "test_prob=pd.DataFrame(oof_test)\n",
    "test_prob.columns=['class1']\n",
    "test_prob.to_csv(\"class_oof/test_prob_%s.csv\"%mean_loss,index=False)\n",
    "\n",
    "np.save(\"train_y\",target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T10:35:46.653584Z",
     "start_time": "2019-02-12T10:35:28.761096Z"
    },
    "_uuid": "40b64481054fa71e692829c7039eccceb31b77fe",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#cv: 3.6497796168629439  lb:3.693\n",
    "cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n",
    "        .groupby(\"Feature\")\n",
    "        .mean()\n",
    "        .sort_values(by=\"importance\", ascending=False)[:500].index)\n",
    "\n",
    "best_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(14,25))\n",
    "sns.barplot(x=\"importance\",\n",
    "            y=\"Feature\",\n",
    "            data=best_features.sort_values(by=\"importance\",\n",
    "                                           ascending=False))\n",
    "plt.title('LightGBM Features (avg over folds)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('lgbm_importances.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-12T10:35:56.375917Z",
     "start_time": "2019-02-12T10:35:55.923600Z"
    },
    "_uuid": "355e9c24949b8e5d677fe5a2f117228c3310dab6"
   },
   "outputs": [],
   "source": [
    "sub_df = pd.DataFrame({\"card_id\":df_test[\"card_id\"].values})\n",
    "sub_df[\"target\"] = oof_test\n",
    "sub_df.to_csv(\"class_sub/submission_%s.csv\"%mean_loss, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
