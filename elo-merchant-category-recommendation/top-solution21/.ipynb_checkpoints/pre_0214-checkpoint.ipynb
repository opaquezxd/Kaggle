{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-16T12:42:09.406347Z",
     "start_time": "2019-02-16T12:42:09.389507Z"
    },
    "_uuid": "b8958a42a498e67832c37c9551c6dbfd0be0e2a5",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "warnings.simplefilter(action='ignore')\n",
    "import gc\n",
    "import dateutil.relativedelta\n",
    "\n",
    "pd.set_option('display.width',None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_info_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.415Z"
    },
    "_uuid": "31d4e7af92eee70ef3c3100f226bff45b78c3389",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def reduce_mem_usage(df, verbose=True):\n",
    "#     numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "#     start_mem = df.memory_usage().sum() / 1024**2    \n",
    "#     for col in df.columns:\n",
    "#         col_type = df[col].dtypes\n",
    "#         if col_type in numerics:\n",
    "#             c_min = df[col].min()\n",
    "#             c_max = df[col].max()\n",
    "#             if str(col_type)[:3] == 'int':\n",
    "#                 if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "#                     df[col] = df[col].astype(np.int8)\n",
    "#                 elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "#                     df[col] = df[col].astype(np.int16)\n",
    "#                 elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "#                     df[col] = df[col].astype(np.int32)\n",
    "#                 elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "#                     df[col] = df[col].astype(np.int64)  \n",
    "#             else:\n",
    "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "#                     df[col] = df[col].astype(np.float16)\n",
    "#                 elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "#                     df[col] = df[col].astype(np.float32)\n",
    "#                 else:\n",
    "#                     df[col] = df[col].astype(np.float64)    \n",
    "#     end_mem = df.memory_usage().sum() / 1024**2\n",
    "#     if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.419Z"
    },
    "_uuid": "6f13aec350464a8aa2edb6bb47849e78eae4cbe0"
   },
   "outputs": [],
   "source": [
    "historical_transactions = pd.read_csv('../input/historical_transactions.csv', parse_dates=['purchase_date'])\n",
    "new_transactions = pd.read_csv('../input/new_merchant_transactions.csv', parse_dates=['purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.421Z"
    }
   },
   "outputs": [],
   "source": [
    "np.percentile(historical_transactions['purchase_amount'], [1, 5, 50, 95, 99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.423Z"
    }
   },
   "outputs": [],
   "source": [
    "np.percentile(new_transactions['purchase_amount'], [1, 5, 50, 95, 99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.426Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# historical_transactions['purchase_amount'] = historical_transactions['purchase_amount'].apply(lambda x: min(x, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.428Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# new_transactions['purchase_amount'] = new_transactions['purchase_amount'].apply(lambda x: min(x, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.434Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "historical_transactions['category_2'] = historical_transactions['category_2'].fillna(-1, )\n",
    "new_transactions['category_2'] = new_transactions['category_2'].fillna(-1, )\n",
    "\n",
    "historical_transactions['category_3'] = historical_transactions['category_3'].map({'A':0, 'B':1, 'C':2})\n",
    "new_transactions['category_3'] = new_transactions['category_3'].map({'A':0, 'B':1, 'C':2})\n",
    "\n",
    "historical_transactions['category_3'] = historical_transactions['category_3'].fillna(-1, )\n",
    "new_transactions['category_3'] = new_transactions['category_3'].fillna(-1, )\n",
    "\n",
    "historical_transactions['merchant_id'] = historical_transactions['merchant_id'].fillna('-1', )\n",
    "new_transactions['merchant_id'] = new_transactions['merchant_id'].fillna('-1', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.440Z"
    }
   },
   "outputs": [],
   "source": [
    "historical_transactions['category_3'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.442Z"
    }
   },
   "outputs": [],
   "source": [
    "historical_transactions['purchase_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.443Z"
    }
   },
   "outputs": [],
   "source": [
    "historical_transactions['purchase_date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.445Z"
    }
   },
   "outputs": [],
   "source": [
    "new_transactions['purchase_date'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.447Z"
    }
   },
   "outputs": [],
   "source": [
    "new_transactions['purchase_date'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.450Z"
    },
    "_uuid": "17b616616c961759c9a62d1e2338eaa3472d3f6b"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "def read_data(input_file):\n",
    "    df = pd.read_csv(input_file)\n",
    "    df['first_active_month'] = pd.to_datetime(df['first_active_month'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = read_data('./data/train.csv')\n",
    "test = read_data('./data/test.csv')\n",
    "\n",
    "target = train['target']\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.452Z"
    }
   },
   "outputs": [],
   "source": [
    "test[test['card_id']=='C_ID_c27b4f80f7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.453Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tmp = historical_transactions[historical_transactions['card_id']=='C_ID_c27b4f80f7']['purchase_date'].min() \n",
    "test['first_active_month'][test['card_id']=='C_ID_c27b4f80f7'] = pd.to_datetime(datetime.date(2017, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.455Z"
    },
    "_uuid": "fdbf54a38a40f8248626242a91d0b39f36235cbf",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# historical_transactions = historical_transactions.head(200)\n",
    "# new_transactions = new_transactions.head(200)\n",
    "# train = train.head(200)\n",
    "# test = test.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.456Z"
    },
    "_uuid": "f4734104e7b433a18e0683ed3c01a41e9959f7e1",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sub_month_lag(x):\n",
    "    return x['purchase_date_first'] - dateutil.relativedelta.relativedelta(months=x['month_lag_first'])\n",
    "\n",
    "def a2p(a, p):\n",
    "    return (a.dt.date - p.dt.date).dt.days\n",
    "\n",
    "# def a2r(a, r):\n",
    "#     return (a.dt.year-r.dt.year)*12 + (a.dt.month - r.dt.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.458Z"
    },
    "_uuid": "3f79948f9d827df3c00a5d65eebde1187ae4610c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarize(df):\n",
    "    for col in ['authorized_flag', 'category_1']:\n",
    "        df[col] = df[col].map({'Y':1, 'N':0})\n",
    "    return df\n",
    "\n",
    "historical_transactions = binarize(historical_transactions)\n",
    "new_transactions = binarize(new_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.460Z"
    },
    "_uuid": "c6290ccb47758ce580ff42c9d1488676cb8daa80",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_fun = {\n",
    "    'authorized_flag': ['mean'], \n",
    "}\n",
    "auth_mean = historical_transactions.groupby(['card_id']).agg(agg_fun)\n",
    "auth_mean.columns = ['_'.join(col).strip() for col in auth_mean.columns.values]\n",
    "auth_mean.reset_index(inplace=True)\n",
    "\n",
    "train = pd.merge(train, auth_mean, on='card_id', how='left')\n",
    "test = pd.merge(test, auth_mean, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.463Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# historical_transactions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.465Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# historical_transactions = historical_transactions[historical_transactions['authorized_flag'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.466Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# historical_transactions.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.469Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_train = train[['card_id', 'first_active_month']]\n",
    "a_test = test[['card_id', 'first_active_month']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.471Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_tmp = pd.concat([a_train,a_test]).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.472Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "historical_transactions = pd.merge(historical_transactions, a_tmp, on='card_id', how='left')\n",
    "new_transactions = pd.merge(new_transactions, a_tmp, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.475Z"
    }
   },
   "outputs": [],
   "source": [
    "historical_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.477Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "historical_transactions['purchase_date'] = pd.to_datetime(historical_transactions['purchase_date'])\n",
    "new_transactions['purchase_date'] = pd.to_datetime(new_transactions['purchase_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.479Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_r(history):\n",
    "    agg_func = {\n",
    "        'month_lag': ['first', ],\n",
    "        'purchase_date': ['first', ],\n",
    "        }\n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    agg_history['reference_date'] = agg_history.apply(sub_month_lag, axis=1)\n",
    "    agg_history['reference_date'] = agg_history['reference_date'].apply(lambda x: x + dateutil.relativedelta.relativedelta(day=1, months=+1, days=-1))\n",
    "    agg_history['now_date'] = agg_history['reference_date'].apply(lambda x: x + dateutil.relativedelta.relativedelta(day=1, months=+5, days=-1))\n",
    "\n",
    "    agg_history.drop(columns=['month_lag_first', 'purchase_date_first'], inplace=True)\n",
    "\n",
    "    return agg_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.480Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hist_r = get_r(historical_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.482Z"
    }
   },
   "outputs": [],
   "source": [
    "hist_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.484Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "historical_transactions = pd.merge(historical_transactions, hist_r, on='card_id', how='left')\n",
    "new_transactions = pd.merge(new_transactions, hist_r, on='card_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.490Z"
    }
   },
   "outputs": [],
   "source": [
    "historical_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.492Z"
    },
    "_uuid": "9dea60659c9e23898c88f9a80f98acc6641e158c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in [historical_transactions, new_transactions]:\n",
    "    df['a2p'] = a2p(df['first_active_month'], df['purchase_date'])\n",
    "    \n",
    "    df['p2r'] = a2p(df['purchase_date'], df['reference_date'])\n",
    "    df['p2now'] = a2p(df['purchase_date'], df['now_date'])\n",
    "    \n",
    "#     df['p_and_m'] = df['purchase_amount'] * (df['month_lag'].abs()+1)\n",
    "    df['p_vs_m'] = df['purchase_amount'] / (df['month_lag'].abs()+1)\n",
    "    \n",
    "    df[\"installments\"].replace(-1, np.NaN, inplace=True)\n",
    "    df[\"installments\"].replace(999, np.NaN, inplace=True)\n",
    "    \n",
    "#     df['p_and_i'] = df['purchase_amount'] * (df['installments'].abs()+1)\n",
    "    df['p_vs_i'] = df['purchase_amount'] / (df['installments'].abs()+1)\n",
    "\n",
    "#     df['year'] = df['purchase_date'].dt.year\n",
    "    df['quarter'] = df['purchase_date'].dt.quarter\n",
    "\n",
    "    df['month'] = df['purchase_date'].dt.month\n",
    "    \n",
    "    df['weekofyear'] = df['purchase_date'].dt.weekofyear\n",
    "    df['dayofweek'] = df['purchase_date'].dt.dayofweek\n",
    "    df['day'] = df['purchase_date'].dt.day\n",
    "    df['hour'] = df['purchase_date'].dt.hour\n",
    "\n",
    "#     df['is_quarter_start'] = (df.purchase_date.dt.is_quarter_start).astype(int)\n",
    "#     df['is_quarter_end'] = (df.purchase_date.dt.is_quarter_end).astype(int)  \n",
    "    df['is_month_start'] = (df.purchase_date.dt.is_month_start).astype(int)\n",
    "#     df['is_month_end'] = (df.purchase_date.dt.is_month_end).astype(int)  \n",
    "\n",
    "    df['weekend'] = (df.purchase_date.dt.weekday>=5).astype(int)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.495Z"
    }
   },
   "outputs": [],
   "source": [
    "historical_transactions['a2p'].plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.497Z"
    }
   },
   "outputs": [],
   "source": [
    "new_transactions['a2p'].plot.line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.501Z"
    }
   },
   "outputs": [],
   "source": [
    "historical_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.503Z"
    },
    "_uuid": "100fb62dd42e8c4057993865451604008a6b3ee0"
   },
   "outputs": [],
   "source": [
    "def aggregate_transactions_hist(history_):\n",
    "        \n",
    "    agg_func = {\n",
    "#         'is_quarter_start': ['sum', 'mean'],\n",
    "#         'is_quarter_end': ['sum', 'mean'],\n",
    "        'is_month_start': ['mean'],\n",
    "#         'is_month_end': ['sum', 'mean'],\n",
    "        'weekend': ['mean'],\n",
    "        'category_1': ['mean'],\n",
    "        #\n",
    "        \n",
    "        'category_2': ['nunique', ], #\n",
    "        'category_3': ['nunique', ], #\n",
    "        'state_id': ['nunique', ],\n",
    "        'city_id': ['nunique', ],\n",
    "        'subsector_id': ['nunique', ],\n",
    "        'merchant_category_id': ['nunique', ],\n",
    "        'merchant_id': ['nunique', ],\n",
    "#         'year': ['nunique', ],\n",
    "        'quarter': ['nunique', ],\n",
    "        'month': ['nunique', ], \n",
    "        'weekofyear': ['nunique', ],\n",
    "        'dayofweek': ['nunique', ],\n",
    "        'day': ['nunique', ],\n",
    "        'hour': ['nunique', ],\n",
    "        \n",
    "        #\n",
    "        'a2p': ['mean', 'median', 'max', 'min', 'std'], \n",
    "        \n",
    "        'p2r': ['mean', 'median', 'max', 'min', 'std'], \n",
    "        'p2now': ['mean', 'median', 'max', 'min', 'std'],  ################\n",
    "        \n",
    "        'month_lag': ['mean', 'median', 'max', 'min', 'std'],\n",
    "        'purchase_amount': ['sum', 'mean', 'median', 'max', 'min', 'std'], \n",
    "        'installments': ['sum', 'mean', 'median', 'max', 'min', 'std'], \n",
    "#         'p_and_m': ['mean', 'median', 'max', 'min', 'std'], \n",
    "        'p_vs_m': ['mean', 'median', 'max', 'min', 'std'],\n",
    "#         'p_and_i': ['mean', 'median', 'max', 'min', 'std'], \n",
    "        'p_vs_i': ['mean', 'median', 'max', 'min', 'std'],\n",
    "        'purchase_date': ['max', 'min'],\n",
    "        'first_active_month': ['first'],\n",
    "        'reference_date': ['first'],\n",
    "        'now_date': ['first'],\n",
    "        }\n",
    "        \n",
    "    history = history_\n",
    "    \n",
    "    for col in ['category_2', 'category_3', \n",
    "                'state_id', 'city_id', 'subsector_id', 'merchant_category_id', 'merchant_id', \n",
    "#                 'year', \n",
    "                'quarter', \n",
    "                'month', 'weekofyear', \n",
    "                'dayofweek',\n",
    "                'day',\n",
    "                'hour'\n",
    "               ]:\n",
    "        \n",
    "#         freq_encode = history[col].value_counts(normalize=True)\n",
    "#         history[col+'_freq'] = history[col].map(freq_encode)\n",
    "        \n",
    "        history[col+'_p_mean'] = history.groupby([col])['purchase_amount'].transform('mean')  # mean encode improve 0.697 to 0.694\n",
    "#         history[col+'_i_mean'] = history.groupby([col])['installments'].transform('mean')\n",
    "\n",
    "#         agg_func[col+'_freq'] = ['mean']\n",
    "\n",
    "#         agg_func[col+'_p_mean'] = ['mean']\n",
    "        agg_func[col+'_p_mean'] = ['mean', 'median', 'max', 'min', 'std']\n",
    "#         agg_func[col+'_i_mean'] = ['mean', 'max', 'min', 'std']\n",
    "\n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    \n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "    \n",
    "    agg_history['first_year'] = agg_history['first_active_month_first'].dt.year\n",
    "    agg_history['first_quarter'] = agg_history['first_active_month_first'].dt.quarter\n",
    "    agg_history['first_month'] = agg_history['first_active_month_first'].dt.month\n",
    "    \n",
    "    agg_history['re_year'] = agg_history['reference_date_first'].dt.year\n",
    "    agg_history['re_quarter'] = agg_history['reference_date_first'].dt.quarter\n",
    "    agg_history['re_month'] = agg_history['reference_date_first'].dt.month\n",
    "    \n",
    "    agg_history['now_year'] = agg_history['now_date_first'].dt.year\n",
    "    agg_history['now_quarter'] = agg_history['now_date_first'].dt.quarter\n",
    "    agg_history['now_month'] = agg_history['now_date_first'].dt.month\n",
    "    \n",
    "    agg_history['a2r'] = a2p(agg_history['first_active_month_first'], agg_history['reference_date_first'])\n",
    "    agg_history['r2now'] = a2p(agg_history['reference_date_first'], agg_history['now_date_first'])\n",
    "    agg_history['a2now'] = a2p(agg_history['first_active_month_first'], agg_history['now_date_first']) #############\n",
    "\n",
    "    agg_history.drop(columns=['first_active_month_first', 'reference_date_first', 'now_date_first'], inplace=True)\n",
    "    \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "    \n",
    "    return agg_history\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.506Z"
    },
    "_uuid": "e3776887c7b3178092fbf84eb34dd966007e39a0"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "history = aggregate_transactions_hist(historical_transactions)\n",
    "    \n",
    "history.columns = ['hist_' + c if c != 'card_id' else c for c in history.columns]\n",
    "\n",
    "history['hist_p2p'] = (history['hist_purchase_date_max'] - history['hist_purchase_date_min']).dt.days\n",
    "history['hist_sleep'] = history['hist_p2p'] - history['hist_day_nunique']\n",
    "\n",
    "###\n",
    "history['hist_p2p_vs_count'] = history['hist_p2p']/history['hist_transactions_count']\n",
    "history['hist_sleep_vs_count'] = history['hist_sleep']/history['hist_transactions_count']\n",
    "###\n",
    "history['hist_count_vs_p2p'] = history['hist_transactions_count']/(history['hist_p2p'].abs()+1)\n",
    "history['hist_sleep_vs_p2p'] = history['hist_sleep']/(history['hist_p2p'].abs()+1)\n",
    "history['hist_p_vs_p2p'] = history['hist_purchase_amount_sum']/(history['hist_p2p'].abs()+1)\n",
    "\n",
    "history['hist_i_vs_p2p'] = history['hist_installments_sum']/(history['hist_p2p'].abs()+1)\n",
    "\n",
    "# history[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.508Z"
    },
    "_uuid": "8512be4cd73baed434e5c8e68c81daf823d4cce9"
   },
   "outputs": [],
   "source": [
    "history.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.510Z"
    },
    "_uuid": "6c7300cc2e089aa14c361be8952fc88f9e16368b"
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, history, on='card_id', how='left')\n",
    "test = pd.merge(test, history, on='card_id', how='left')\n",
    "del history; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.512Z"
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_transactions_new(history_):\n",
    "        \n",
    "    agg_func = {\n",
    "#         'is_quarter_start': ['sum', 'mean'],\n",
    "#         'is_quarter_end': ['sum', 'mean'],\n",
    "        'is_month_start': ['mean'],\n",
    "#         'is_month_end': ['sum', 'mean'],\n",
    "        'weekend': ['mean'],\n",
    "        'category_1': ['mean'],\n",
    "        #\n",
    "        \n",
    "        'category_2': ['nunique', ], #\n",
    "        'category_3': ['nunique', ], #\n",
    "        'state_id': ['nunique', ],\n",
    "        'city_id': ['nunique', ],\n",
    "        'subsector_id': ['nunique', ],\n",
    "        'merchant_category_id': ['nunique', ],\n",
    "        'merchant_id': ['nunique', ],\n",
    "#         'year': ['nunique', ],\n",
    "        'quarter': ['nunique', ],\n",
    "        'month': ['nunique', ], \n",
    "        'weekofyear': ['nunique', ],\n",
    "        'dayofweek': ['nunique', ],\n",
    "        'day': ['nunique', ],\n",
    "        'hour': ['nunique', ],\n",
    "        \n",
    "        #\n",
    "        'a2p': ['mean', 'median', 'max', 'min', 'std'],  ################\n",
    "        \n",
    "        'p2r': ['mean', 'median', 'max', 'min', 'std'], \n",
    "        'p2now': ['mean', 'median', 'max', 'min', 'std'], \n",
    "        \n",
    "        'month_lag': ['mean', 'median', 'max', 'min', 'std'],\n",
    "        'purchase_amount': ['sum', 'mean', 'median', 'max', 'min', 'std'], # \n",
    "        'installments': ['sum', 'mean', 'median', 'max', 'min', 'std'], # \n",
    "#         'p_and_m': ['mean', 'median', 'max', 'min', 'std'], # \n",
    "        'p_vs_m': ['mean', 'median', 'max', 'min', 'std'], # \n",
    "#         'p_and_i': ['mean', 'median', 'max', 'min', 'std'], # \n",
    "        'p_vs_i': ['mean', 'median', 'max', 'min', 'std'], # \n",
    "        'purchase_date': ['max', 'min'],\n",
    "        }\n",
    "        \n",
    "    history = history_\n",
    "    \n",
    "    for col in ['category_2', 'category_3', \n",
    "                'state_id', 'city_id', 'subsector_id', 'merchant_category_id', 'merchant_id', \n",
    "#                 'year', \n",
    "                'quarter', \n",
    "                'month', 'weekofyear', \n",
    "                'dayofweek',\n",
    "                'day',\n",
    "                'hour'\n",
    "               ]:\n",
    "        \n",
    "#         freq_encode = history[col].value_counts(normalize=True)\n",
    "#         history[col+'_freq'] = history[col].map(freq_encode)\n",
    "        \n",
    "        history[col+'_p_mean'] = history.groupby([col])['purchase_amount'].transform('mean')  # mean encode import 0.697 to 0.694\n",
    "#         history[col+'_i_mean'] = history.groupby([col])['installments'].transform('mean')\n",
    "\n",
    "#         agg_func[col+'_freq'] = ['mean']\n",
    "\n",
    "#         agg_func[col+'_p_mean'] = ['mean']\n",
    "        agg_func[col+'_p_mean'] = ['mean', 'median', 'max', 'min', 'std']\n",
    "#         agg_func[col+'_i_mean'] = ['mean', 'max', 'min', 'std']\n",
    "\n",
    "    agg_history = history.groupby(['card_id']).agg(agg_func)\n",
    "    \n",
    "    agg_history.columns = ['_'.join(col).strip() for col in agg_history.columns.values]\n",
    "    agg_history.reset_index(inplace=True)\n",
    "        \n",
    "    df = (history.groupby('card_id')\n",
    "          .size()\n",
    "          .reset_index(name='transactions_count'))\n",
    "    \n",
    "    agg_history = pd.merge(df, agg_history, on='card_id', how='left')\n",
    "        \n",
    "    return agg_history\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.514Z"
    },
    "_uuid": "2993a4564e3a2d43ef07608f8cd0b8506dcf9534"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "new = aggregate_transactions_new(new_transactions)\n",
    "    \n",
    "new.columns = ['new_' + c if c != 'card_id' else c for c in new.columns]\n",
    "    \n",
    "new['new_p2p'] = (new['new_purchase_date_max'] - new['new_purchase_date_min']).dt.days\n",
    "new['new_sleep'] = new['new_p2p'] - new['new_day_nunique']\n",
    "###\n",
    "new['new_p2p_vs_count'] = new['new_p2p']/new['new_transactions_count']\n",
    "new['new_sleep_vs_count'] = new['new_sleep']/new['new_transactions_count']\n",
    "###\n",
    "new['new_count_vs_p2p'] = new['new_transactions_count']/(new['new_p2p'].abs()+1)\n",
    "new['new_sleep_vs_p2p'] = new['new_sleep']/(new['new_p2p'].abs()+1)\n",
    "new['new_p_vs_p2p'] = new['new_purchase_amount_sum']/(new['new_p2p'].abs()+1)\n",
    "\n",
    "new['new_i_vs_p2p'] = new['new_installments_sum']/(new['new_p2p'].abs()+1)\n",
    "\n",
    "# new[:5]\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.517Z"
    },
    "_uuid": "b7641bb89fd128e8f8dd4d6fe4dd81204374a4db"
   },
   "outputs": [],
   "source": [
    "new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.518Z"
    },
    "_uuid": "d0694e8b09e2b0083a513847cb37d1e92bd1d857"
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, new, on='card_id', how='left')\n",
    "test = pd.merge(test, new, on='card_id', how='left')\n",
    "del new; gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.521Z"
    },
    "_uuid": "74ead56ad710a0c794a5b8130f24f52f53207c6c"
   },
   "outputs": [],
   "source": [
    "train['outliers'] = 0\n",
    "train.loc[train['target'] < -30, 'outliers'] = 1\n",
    "train['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.523Z"
    },
    "_uuid": "26145f27174d035be2200802bb3afbb831341499",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for df in [train, test]:\n",
    "    ###\n",
    "    df['c_p2p_diff'] = df['hist_p2p_vs_count'] - df['new_p2p_vs_count']\n",
    "    df['c_sleep_diff'] = df['hist_sleep_vs_count'] - df['new_sleep_vs_count']\n",
    "    df['c_p_diff'] = df['hist_purchase_amount_mean'] - df['new_purchase_amount_mean']\n",
    "    df['c_i_diff'] = df['hist_installments_mean'] - df['new_installments_mean']\n",
    "    ###\n",
    "    df['p2p_count_diff'] = df['hist_count_vs_p2p'] - df['new_count_vs_p2p']\n",
    "    df['p2p_sleep_diff'] = df['hist_sleep_vs_p2p'] - df['new_sleep_vs_p2p']\n",
    "    df['p2p_p_diff'] = df['hist_p_vs_p2p'] - df['new_p_vs_p2p']\n",
    "    df['p2p_i_diff'] = df['hist_i_vs_p2p'] - df['new_i_vs_p2p']\n",
    "    ###\n",
    "    df['c_p2p_diff_vs'] = df['c_p2p_diff'] / df['hist_p2p_vs_count']\n",
    "    df['c_sleep_diff_vs'] = df['c_sleep_diff'] / df['hist_sleep_vs_count']\n",
    "    df['c_p_diff_vs']  = df['c_p_diff'] / df['hist_purchase_amount_mean']\n",
    "    df['c_i_diff_vs'] = df['c_i_diff'] / df['hist_installments_mean']\n",
    "    ###\n",
    "    df['p2p_count_diff_vs'] = df['p2p_count_diff'] / df['hist_count_vs_p2p']\n",
    "    df['p2p_sleep_diff_vs'] = df['p2p_sleep_diff'] / df['hist_sleep_vs_p2p']\n",
    "    df['p2p_p_diff_vs']  = df['p2p_p_diff'] / df['hist_p_vs_p2p']\n",
    "    df['p2p_i_diff_vs'] = df['p2p_i_diff'] / df['hist_i_vs_p2p']\n",
    "    ###\n",
    "#     df['count_sum'] = df['hist_transactions_count'] + df['new_transactions_count']\n",
    "#     df['p_sum'] = df['hist_purchase_amount_sum'] + df['new_purchase_amount_sum']\n",
    "#     df['i_sum'] = df['hist_installments_sum'] + df['new_installments_sum']\n",
    "#     df['p_sum_vs_count'] = df['p_sum'] / df['count_sum'] # mean\n",
    "#     df['i_sum_vs_count'] = df['i_sum'] / df['count_sum'] # mean\n",
    "    ###\n",
    "#     df['gap'] = a2p(df['hist_purchase_date_max'], df['new_purchase_date_min'])\n",
    "    ###\n",
    "#     df['time'] = a2p(df['hist_purchase_date_min'], df['new_purchase_date_max'])\n",
    "#     df['sleep_sum'] = df['hist_sleep'] + df['new_sleep']\n",
    "\n",
    "#     df['time_vs_count'] = df['time'] / df['count_sum']\n",
    "#     df['sleep_sum_vs_count'] = df['sleep_sum'] / df['count_sum']\n",
    "    \n",
    "#     df['count_sum_vs_time'] = df['count_sum'] / (df['time'].abs() + 1)\n",
    "#     df['sleep_sum_vs_time'] = df['sleep_sum'] / (df['time'].abs() + 1)\n",
    "#     df['p_sum_vs_time'] = df['p_sum'] / (df['time'].abs() + 1)\n",
    "#     df['i_sum_vs_time'] = df['i_sum'] / (df['time'].abs() + 1)\n",
    "    ###\n",
    "    \n",
    "    ###\n",
    "    for f in ['hist_purchase_date_max','hist_purchase_date_min', \n",
    "              'new_purchase_date_max', 'new_purchase_date_min']:\n",
    "        df[f] = df[f].astype(np.int64) * 1e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.526Z"
    }
   },
   "outputs": [],
   "source": [
    "train['hist_p2p'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.528Z"
    }
   },
   "outputs": [],
   "source": [
    "train['new_p2p'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.530Z"
    }
   },
   "outputs": [],
   "source": [
    "train['hist_sleep'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.531Z"
    }
   },
   "outputs": [],
   "source": [
    "train['new_sleep'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.534Z"
    }
   },
   "outputs": [],
   "source": [
    "train['c_p2p_diff'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.535Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train['c_sleep_diff'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.536Z"
    }
   },
   "outputs": [],
   "source": [
    "train['c_p_diff'].apply(lambda x: min(x, 10)).plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.538Z"
    }
   },
   "outputs": [],
   "source": [
    "train['c_i_diff'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.541Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train['p2p_sleep_diff'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.542Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# train['p2p_count_diff'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.544Z"
    }
   },
   "outputs": [],
   "source": [
    "train['p2p_p_diff'].apply(lambda x: min(x, 10)).plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.546Z"
    }
   },
   "outputs": [],
   "source": [
    "train['p2p_i_diff'].plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.548Z"
    },
    "_uuid": "b878fe07f659181737a4f421a560e0d529c96024"
   },
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.550Z"
    }
   },
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.552Z"
    }
   },
   "outputs": [],
   "source": [
    "train['authorized_flag_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.553Z"
    }
   },
   "outputs": [],
   "source": [
    "test['authorized_flag_mean'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.557Z"
    },
    "_uuid": "d713aa6465f715d23fa3ab7e5135876c3e85bd02"
   },
   "outputs": [],
   "source": [
    "print(\"Train Shape:\", train.shape)\n",
    "print(\"Test Shape:\", test.shape)\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.559Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summary(df):\n",
    "    stats = []\n",
    "    for col in df.columns:\n",
    "        stats.append((col, df[col].nunique(), \n",
    "                      df[col].isnull().sum() * 100 / df.shape[0], \n",
    "                      df[col].value_counts(normalize=True, dropna=False).values[0] * 100, \n",
    "                      df[col].dtype))\n",
    "    \n",
    "    return pd.DataFrame(stats, columns=['feature', 'unique', 'missing', 'mode', 'type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.562Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_summary = summary(train)\n",
    "test_summary = summary(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.563Z"
    },
    "_uuid": "79cf64d792789378d402f4584366c3682c7f76fd",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp_1 = train_summary.sort_values('mode', ascending=False)\n",
    "tmp_2 = test_summary.sort_values('mode', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.565Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.567Z"
    },
    "_uuid": "7b3ccca587ec801a969a8153c7449215e13c60dd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "dc4aca7bfb216d5d4f4f603ec91a9cfe47bdd8c6",
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.570Z"
    },
    "_uuid": "2b167b952809281e69c9d978b0d05cf8d54c06d9",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train.to_csv(\"./data/pre_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.571Z"
    },
    "_uuid": "da87fcebd96be92f03a05b2eef6c5c24b9b51374",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test.to_csv(\"./data/pre_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.573Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmp = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.575Z"
    }
   },
   "outputs": [],
   "source": [
    "tmp.plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.576Z"
    }
   },
   "outputs": [],
   "source": [
    "(tmp*np.log10(2)).plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-02-16T12:42:09.578Z"
    }
   },
   "outputs": [],
   "source": [
    "np.log2((np.exp2(tmp) - 0.0000000001) + 1).plot.hist(bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
